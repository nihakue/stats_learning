{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "require(MASS)\n",
    "require(ISLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "# Make origin a factor and remove the name predictor\n",
    "auto.nn$origin2 <- ifelse(auto.nn$origin == 2, 1, 0)\n",
    "auto.nn$origin3 <- ifelse(auto.nn$origin == 3, 1, 0)\n",
    "\n",
    "auto.nn <- subset(Auto, select=-c(name, origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  mpg cylinders displacement horsepower weight acceleration year\n",
       "1  18         8          307        130   3504         12.0   70\n",
       "2  15         8          350        165   3693         11.5   70\n",
       "3  18         8          318        150   3436         11.0   70\n",
       "4  16         8          304        150   3433         12.0   70\n",
       "5  17         8          302        140   3449         10.5   70\n",
       "6  15         8          429        198   4341         10.0   70\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "head(auto.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "fit <- lm(mpg~origin, data=auto.nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ origin, data = auto.nn)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-12.451  -5.034  -1.034   3.649  18.966 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  20.0335     0.4086  49.025   <2e-16 ***\n",
       "origin2       7.5695     0.8767   8.634   <2e-16 ***\n",
       "origin3      10.4172     0.8276  12.588   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 6.396 on 389 degrees of freedom\n",
       "Multiple R-squared:  0.3318,\tAdjusted R-squared:  0.3284 \n",
       "F-statistic:  96.6 on 2 and 389 DF,  p-value: < 2.2e-16\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in eval(expr, envir, enclos) : object 'origin3' not found\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(leaps)\n",
    "regfit.full <- regsubsets(mpg~., data=auto.nn)\n",
    "summary.reg <- summary(regfit.full)\n",
    "predictors <- regfit.full$xnames[-1]\n",
    "num.ss <- 8\n",
    "errs <- rep(NA, num.ss)\n",
    "for (i in 1:nrow(summary.reg$which)){\n",
    "    preds <- predictors[summary.reg$which[i, -1]]\n",
    "    form <- as.formula(paste('mpg', paste(preds, collapse=\"+\"), sep=\" ~ \"))\n",
    "    fit <- glm(form, data=auto.nn)\n",
    "    errs[[i]] <- (cv.glm(auto.nn, form, K=10)$delta)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " [1] \"np\"        \"nrbar\"     \"d\"         \"rbar\"      \"thetab\"    \"first\"    \n",
       " [7] \"last\"      \"vorder\"    \"tol\"       \"rss\"       \"bound\"     \"nvmax\"    \n",
       "[13] \"ress\"      \"ir\"        \"nbest\"     \"lopt\"      \"il\"        \"ier\"      \n",
       "[19] \"xnames\"    \"method\"    \"force.in\"  \"force.out\" \"sserr\"     \"intercept\"\n",
       "[25] \"lindep\"    \"nullrss\"   \"nn\"        \"call\"     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "names(regfit.full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"       \"acceleration\"\n",
       "[6] \"year\"         \"origin2\"      \"origin3\"     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "regfit.full$xnames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 11.38900 11.35042\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(boot)\n",
    "cv.error <- rep(0, 8)\n",
    "for (i in 1:8){\n",
    "    glm.fit <- glm(mpg ~., data=auto.nn\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"mpg ~ cylinders + horsepower\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "fit <- lm(as.formula(paste('mpg', paste(c('cylinders', 'horsepower'), collapse=\"+\"), sep=\" ~ \")), data=auto.nn)\n",
    "paste('mpg', paste(c('cylinders', 'horsepower'), collapse=\" + \"), sep=\" ~ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Help on ‘cv.glm’cv.glm                  package:boot                   R Documentation\n",
      "\n",
      "_\bC_\br_\bo_\bs_\bs-_\bv_\ba_\bl_\bi_\bd_\ba_\bt_\bi_\bo_\bn _\bf_\bo_\br _\bG_\be_\bn_\be_\br_\ba_\bl_\bi_\bz_\be_\bd _\bL_\bi_\bn_\be_\ba_\br _\bM_\bo_\bd_\be_\bl_\bs\n",
      "\n",
      "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
      "\n",
      "     This function calculates the estimated K-fold cross-validation\n",
      "     prediction error for generalized linear models.\n",
      "\n",
      "_\bU_\bs_\ba_\bg_\be:\n",
      "\n",
      "     cv.glm(data, glmfit, cost, K)\n",
      "     \n",
      "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
      "\n",
      "    data: A matrix or data frame containing the data.  The rows should\n",
      "          be cases and the columns correspond to variables, one of\n",
      "          which is the response.\n",
      "\n",
      "  glmfit: An object of class ‘\"glm\"’ containing the results of a\n",
      "          generalized linear model fitted to ‘data’.\n",
      "\n",
      "    cost: A function of two vector arguments specifying the cost\n",
      "          function for the cross-validation.  The first argument to\n",
      "          ‘cost’ should correspond to the observed responses and the\n",
      "          second argument should correspond to the predicted or fitted\n",
      "          responses from the generalized linear model.  ‘cost’ must\n",
      "          return a non-negative scalar value.  The default is the\n",
      "          average squared error function.\n",
      "\n",
      "       K: The number of groups into which the data should be split to\n",
      "          estimate the cross-validation prediction error.  The value of\n",
      "          ‘K’ must be such that all groups are of approximately equal\n",
      "          size.  If the supplied value of ‘K’ does not satisfy this\n",
      "          criterion then it will be set to the closest integer which\n",
      "          does and a warning is generated specifying the value of ‘K’\n",
      "          used.  The default is to set ‘K’ equal to the number of\n",
      "          observations in ‘data’ which gives the usual leave-one-out\n",
      "          cross-validation.\n",
      "\n",
      "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
      "\n",
      "     The data is divided randomly into ‘K’ groups.  For each group the\n",
      "     generalized linear model is fit to ‘data’ omitting that group,\n",
      "     then the function ‘cost’ is applied to the observed responses in\n",
      "     the group that was omitted from the fit and the prediction made by\n",
      "     the fitted models for those observations.\n",
      "\n",
      "     When ‘K’ is the number of observations leave-one-out\n",
      "     cross-validation is used and all the possible splits of the data\n",
      "     are used.  When ‘K’ is less than the number of observations the\n",
      "     ‘K’ splits to be used are found by randomly partitioning the data\n",
      "     into ‘K’ groups of approximately equal size.  In this latter case\n",
      "     a certain amount of bias is introduced.  This can be reduced by\n",
      "     using a simple adjustment (see equation 6.48 in Davison and\n",
      "     Hinkley, 1997). The second value returned in ‘delta’ is the\n",
      "     estimate adjusted by this method.\n",
      "\n",
      "_\bV_\ba_\bl_\bu_\be:\n",
      "\n",
      "     The returned value is a list with the following components.\n",
      "\n",
      "    call: The original call to ‘cv.glm’.\n",
      "\n",
      "       K: The value of ‘K’ used for the K-fold cross validation.\n",
      "\n",
      "   delta: A vector of length two.  The first component is the raw\n",
      "          cross-validation estimate of prediction error.  The second\n",
      "          component is the adjusted cross-validation estimate.  The\n",
      "          adjustment is designed to compensate for the bias introduced\n",
      "          by not using leave-one-out cross-validation.\n",
      "\n",
      "    seed: The value of ‘.Random.seed’ when ‘cv.glm’ was called.\n",
      "\n",
      "_\bS_\bi_\bd_\be _\bE_\bf_\bf_\be_\bc_\bt_\bs:\n",
      "\n",
      "     The value of ‘.Random.seed’ is updated.\n",
      "\n",
      "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
      "\n",
      "     Breiman, L., Friedman, J.H., Olshen, R.A. and Stone, C.J. (1984)\n",
      "     _Classification and Regression Trees_. Wadsworth.\n",
      "\n",
      "     Burman, P. (1989) A comparative study of ordinary\n",
      "     cross-validation, _v_-fold cross-validation and repeated\n",
      "     learning-testing methods. _Biometrika_, *76*, 503-514\n",
      "\n",
      "     Davison, A.C. and Hinkley, D.V. (1997) _Bootstrap Methods and\n",
      "     Their Application_. Cambridge University Press.\n",
      "\n",
      "     Efron, B. (1986) How biased is the apparent error rate of a\n",
      "     prediction rule? _Journal of the American Statistical\n",
      "     Association_, *81*, 461-470.\n",
      "\n",
      "     Stone, M.  (1974) Cross-validation choice and assessment of\n",
      "     statistical predictions (with Discussion).  _Journal of the Royal\n",
      "     Statistical Society, B_, *36*, 111-147.\n",
      "\n",
      "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
      "\n",
      "     ‘glm’, ‘glm.diag’, ‘predict’\n",
      "\n",
      "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
      "\n",
      "     # leave-one-out and 6-fold cross-validation prediction error for \n",
      "     # the mammals data set.\n",
      "     data(mammals, package=\"MASS\")\n",
      "     mammals.glm <- glm(log(brain) ~ log(body), data = mammals)\n",
      "     (cv.err <- cv.glm(mammals, mammals.glm)$delta)\n",
      "     (cv.err.6 <- cv.glm(mammals, mammals.glm, K = 6)$delta)\n",
      "     \n",
      "     # As this is a linear model we could calculate the leave-one-out \n",
      "     # cross-validation estimate without any extra model-fitting.\n",
      "     muhat <- fitted(mammals.glm)\n",
      "     mammals.diag <- glm.diag(mammals.glm)\n",
      "     (cv.err <- mean((mammals.glm$y - muhat)^2/(1 - mammals.diag$h)^2))\n",
      "     \n",
      "     \n",
      "     # leave-one-out and 11-fold cross-validation prediction error for \n",
      "     # the nodal data set.  Since the response is a binary variable an\n",
      "     # appropriate cost function is\n",
      "     cost <- function(r, pi = 0) mean(abs(r-pi) > 0.5)\n",
      "     \n",
      "     nodal.glm <- glm(r ~ stage+xray+acid, binomial, data = nodal)\n",
      "     (cv.err <- cv.glm(nodal, nodal.glm, cost, K = nrow(nodal))$delta)\n",
      "     (cv.11.err <- cv.glm(nodal, nodal.glm, cost, K = 11)$delta)\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "help(cv.glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
